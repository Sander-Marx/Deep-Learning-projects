{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF 265 - Deep learning: Project 3 - Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read txt files and tokenize them to obtain train/validation/test lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_EN = get_tokenizer('basic_english')\n",
    "PATH_GENERATED = './generated/'\n",
    "# Minimum number of occurence of a word in the text to add it to the vocabulary\n",
    "MIN_FREQ = 100\n",
    "\n",
    "\n",
    "def read_files(datapath=\"./\"):\n",
    "    files = os.listdir(datapath)\n",
    "    files = [datapath + f for f in files if f.endswith(\".txt\")]\n",
    "\n",
    "    lines = []\n",
    "    for f_name in files:\n",
    "        with open(f_name, encoding='utf-8') as f:\n",
    "            lines += f.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "def tokenize(lines, tokenizer=TOKENIZER_EN):\n",
    "    \"\"\"\n",
    "    Tokenize the list of lines\n",
    "    \"\"\"\n",
    "    list_text = []\n",
    "    for line in lines:\n",
    "        list_text += tokenizer(line)\n",
    "    return list_text\n",
    "\n",
    "\n",
    "def yield_tokens(lines, tokenizer=TOKENIZER_EN):\n",
    "    \"\"\"\n",
    "    Yield tokens, ignoring names and digits to build vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    no_digits = '\\w*[0-9]+\\w*'\n",
    "    no_names = '\\w*[A-Z]+\\w*'\n",
    "    no_spaces = '\\s+'\n",
    "    \n",
    "    for line in lines:\n",
    "        line = re.sub(no_digits, ' ', line)\n",
    "        line = re.sub(no_names, ' ', line)\n",
    "        line = re.sub(no_spaces, ' ', line)\n",
    "        yield tokenizer(line)\n",
    "\n",
    "def count_freqs(words, vocab):\n",
    "    \"\"\"\n",
    "    Count occurrences of each word in vocabulary in the data\n",
    "    \n",
    "    Useful to get some insight on the data and to compute loss weights\n",
    "    \"\"\"\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs\n",
    "\n",
    "\n",
    "\n",
    "def create_vocabulary(lines, min_freq=MIN_FREQ):\n",
    "    \"\"\"\n",
    "    Create a vocabulary (list of known tokens) from a list of strings\n",
    "    \"\"\"\n",
    "    # vocab contains the vocabulary found in the data, associating an index to each word\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"])\n",
    "    # Since we removed all words with an uppercase when building the vocabulary, we skipped the word \"I\"\n",
    "    vocab.append_token(\"i\")\n",
    "    # Value of default index. This index will be returned when OOV (Out Of Vocabulary) token is queried.\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a vocabulary based on the training dataset. To avoid getting a too large vocabulary,\n",
    "we keep only words that appear at least 100 times in the training dataset.\n",
    "Report the total number of words in the training dataset, the number of distinct words in the\n",
    "training dataset, and the size of the defined vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset:      2684706\n",
      "Total number of words in the validation dataset:    49526\n",
      "Total number of words in the test dataset:          124152\n",
      "Number of distinct words in the training dataset:   52105\n",
      "Number of distinct words kept (vocabulary size):    1880\n",
      "occurences:\n",
      " [(433907, '<unk>'), (182537, ','), (151278, 'the'), (123727, '.'), (82289, 'and'), (65661, 'of'), (62763, 'to'), (49230, 'a'), (41477, 'in'), (31052, 'that'), (37167, 'he'), (29046, 'was'), (26508, 'his'), (26354, 'it'), (20862, 'with'), (20159, 'had'), (19965, 'is'), (15692, 'not'), (16593, 'as'), (15705, 'on'), (14464, 'him'), (15317, 'for'), (15838, 'at'), (15952, 'you'), (13255, 'be'), (12698, 'her'), (12798, 's'), (11924, 'which'), (11808, '!'), (11740, 'all'), (10338, '?'), (10205, 'have'), (10405, 'from'), (13251, 'but'), (11464, 'this'), (9439, 'by'), (11496, 'they'), (8797, 'said'), (8800, 'are'), (11055, 'she'), (9537, 'one'), (8219, 'were'), (8564, 'who'), (8345, 'so'), (9409, 'there'), (7072, 'or'), (6575, 'me'), (6478, 'them'), (6429, 'an'), (6868, 'my'), (5849, 'will'), (5692, 'man'), (7485, 'we'), (5641, 'up'), (5769, 'their'), (5510, 'out'), (5446, 'been'), (7638, 'when'), (6616, 'no'), (5164, 'would'), (7378, 'what'), (4643, 'into'), (5716, 'if'), (4257, 'more'), (4107, 'very'), (3956, 'could'), (3981, 'did'), (3834, 'men'), (3817, 'has'), (4231, 'do'), (6231, 'then'), (4105, 'some'), (7038, 'king'), (3679, 'other'), (3585, 'time'), (3617, 'about'), (3563, 'should'), (3480, 'went'), (3458, 'himself'), (3381, 'came'), (4406, 'now'), (3615, 'only'), (3551, 'your'), (3306, 'like'), (3406, 'two'), (3285, 'little'), (3193, 'before'), (3009, 'over'), (2975, 'made'), (2947, 'than'), (3011, 'see'), (3092, 'may'), (2844, 'down'), (2857, 'old'), (2748, 'us'), (2702, 'know'), (2831, 'can'), (2934, 'good'), (3070, 'where'), (2711, 't'), (2604, '('), (2604, ')'), (2605, 'must'), (2712, 'great'), (2744, 'our'), (2647, 'people'), (2746, 'go'), (2620, 'again'), (2818, 'come'), (2475, 'its'), (2897, 'these'), (3020, 'after'), (2339, 'any'), (2388, 'without'), (2287, 'day'), (2301, 'upon'), (2249, 'eyes'), (1057, 'â€”'), (2311, 'first'), (2224, 'way'), (2205, 'back'), (2171, 'away'), (2169, 'am'), (2142, 'same'), (2277, 'those'), (2125, 'thought'), (2996, 'well'), (2141, 'say'), (2109, 'took'), (2246, 'such'), (2130, 'long'), (2046, 'much'), (1980, 'hand'), (2053, 'still'), (1924, 'face'), (2708, 'how'), (1982, 'through'), (2372, 'here'), (1904, 'head'), (336, '-'), (2128, 'nothing'), (2040, 'many'), (1918, 'shall'), (1981, 'even'), (1855, 'off'), (2061, 'just'), (1754, 'own'), (1752, 'left'), (1738, 'saw'), (1769, 'life'), (1729, 'house'), (1683, 'also'), (1668, 'room'), (1651, 'heard'), (1678, 'too'), (1678, 'being'), (1706, 'make'), (1786, 'never'), (1787, 'take'), (1728, 'once'), (1635, 'night'), (1732, 'each'), (1637, 'most'), (1567, 'door'), (1567, 'seemed'), (1635, 'under'), (1615, 'place'), (1582, 'last'), (1543, 'right'), (1676, 'another'), (1494, 'whole'), (1476, 'asked'), (1462, 'began'), (1620, 'every'), (1504, 'something'), (1438, 'called'), (1473, 'young'), (1415, 'moment'), (1429, 'against'), (1392, 'looked'), (1450, 'get'), (1437, 'things'), (1390, 'might'), (1413, 'think'), (1463, 'three'), (1365, 'told'), (1359, 'felt'), (1621, 'father'), (1338, 'found'), (1357, 'always'), (1291, 'got'), (1311, 'set'), (1307, 'put'), (1840, 'let'), (1265, 'side'), (1242, 'gave'), (1226, 'seen'), (1227, 'round'), (1207, 'turned'), (1296, 'give'), (1216, 'whom'), (1208, 'country'), (1363, 'look'), (1305, 'though'), (1269, 'both'), (1431, 'while'), (1232, 'between'), (1183, 'going'), (1165, 'done'), (1258, 'tell'), (1157, 'woman'), (1222, 'because'), (1272, 'having'), (1109, 'taken'), (1120, 'army'), (1191, 'yet'), (1087, 'says'), (1105, 'light'), (1076, 'knew'), (1145, 'soon'), (1112, 'plants'), (1063, 'few'), (1051, 'part'), (1065, 'son'), (1066, 'others'), (1031, 'years'), (1028, 'voice'), (1020, 'hands'), (1069, 'love'), (1027, 'large'), (1013, 'morning'), (1022, 'end'), (997, 'themselves'), (1043, 'quite'), (995, 'words'), (982, 'stood'), (1033, 'behind'), (1209, 'thing'), (956, 'replied'), (1005, 'battle'), (1027, 'white'), (958, 'along'), (959, 'far'), (946, 'together'), (964, 'water'), (932, 'feet'), (930, 'ground'), (931, 'brought'), (935, 'home'), (923, 'anything'), (930, 'small'), (1047, 'everything'), (1162, 'don'), (917, 'mind'), (893, 'longer'), (889, 'name'), (911, 'already'), (955, 'does'), (886, 'find'), (892, 'wife'), (881, 'fell'), (876, 'word'), (904, 'order'), (963, 'death'), (864, 'matter'), (1046, 'mother'), (857, 'passed'), (856, 'herself'), (871, 'open'), (880, 'near'), (857, 'lay'), (839, 'll'), (842, 'child'), (838, 'sat'), (834, 'best'), (857, 'land'), (837, 'work'), (827, 'remained'), (826, 'bed'), (913, 'among'), (839, 'better'), (823, 'heart'), (822, 'alone'), (824, 'evening'), (878, 'dear'), (814, 'full'), (819, 'de'), (803, 'days'), (797, 'air'), (790, 'sent'), (846, 'poor'), (797, 'friend'), (880, 'new'), (766, 'front'), (860, 'since'), (758, 'sort'), (813, 'four'), (745, 'want'), (762, 'almost'), (742, 'given'), (741, 'table'), (742, 'became'), (747, 'dead'), (723, 'held'), (725, 'cannot'), (742, 'fire'), (719, 'ran'), (733, 'ever'), (763, 'nor'), (709, 'myself'), (765, 'towards'), (784, 'black'), (704, 'case'), (864, 'thou'), (698, 'cried'), (702, 'understand'), (714, 'looking'), (732, 'fall'), (807, 'suddenly'), (684, 'become'), (679, 'answered'), (683, 'ready'), (697, 'until'), (668, 'returned'), (704, 'leave'), (679, 'winter'), (672, 'gone'), (666, 'world'), (693, 'cut'), (662, 'used'), (771, 'general'), (679, 'often'), (655, 'daughter'), (660, 'power'), (651, 'soul'), (1308, 'why'), (643, 'entered'), (826, 'however'), (641, 'itself'), (641, 'possible'), (710, 'war'), (658, 'coming'), (642, 'arms'), (638, 'smile'), (661, 'true'), (635, 'window'), (670, 'half'), (658, 'whose'), (637, 'saying'), (638, 'point'), (635, 'less'), (649, 'rather'), (637, 'enough'), (629, 'laid'), (641, 'speak'), (646, 'certain'), (615, 'earth'), (1311, 'earl'), (607, 'fact'), (609, 'received'), (600, 'hour'), (652, 'red'), (615, 'garden'), (631, 'above'), (599, 'ships'), (595, 'hundred'), (587, 'opened'), (587, 'spoke'), (588, 'girl'), (585, 'lost'), (585, 'continued'), (591, 'ship'), (595, 'trees'), (603, 'horse'), (598, 'around'), (577, 'money'), (570, 'body'), (591, 'brother'), (573, 'hear'), (618, 'keep'), (578, 'spring'), (570, 'town'), (580, 'second'), (581, 'use'), (561, 'hair'), (559, 'rest'), (559, 'cold'), (569, 'terrible'), (565, 'close'), (557, 'course'), (566, 'high'), (564, 'husband'), (553, 'added'), (563, 'killed'), (555, 'met'), (573, 'road'), (665, 'sometimes'), (564, 'sound'), (559, 'children'), (564, 'within'), (590, 'whether'), (558, 'help'), (542, 'followed'), (545, 'making'), (716, 'thus'), (542, 'year'), (582, 'five'), (578, 'flowers'), (537, 'kept'), (713, 'o'), (545, 'taking'), (546, 'turn'), (536, 'present'), (528, 've'), (529, 'yourself'), (605, 'early'), (613, 'next'), (529, 'times'), (533, 'dark'), (546, 'force'), (523, 'necessary'), (525, 'officer'), (520, 'able'), (526, 'sleep'), (540, 'till'), (523, 'happened'), (533, 'either'), (525, 'short'), (511, 'wish'), (507, 'placed'), (604, 'street'), (512, 'fear'), (506, 'known'), (502, 'need'), (525, 'rose'), (502, 'wanted'), (528, 'fine'), (526, 'letter'), (520, 'ask'), (999, 'count'), (512, 'happy'), (497, 'question'), (494, 'wall'), (494, 'idea'), (500, 'care'), (498, 'feeling'), (504, 'soldiers'), (491, 'clock'), (497, 'past'), (486, 'appeared'), (494, 'blood'), (513, 'beside'), (503, 'talk'), (477, 'carried'), (477, 'raised'), (538, 'later'), (598, 'during'), (483, 'following'), (475, 'soil'), (503, 'hold'), (502, 'evidently'), (482, 'peace'), (468, 'corner'), (484, 'late'), (514, 'really'), (472, 'return'), (467, 'line'), (464, 'horses'), (463, 'arm'), (468, 're'), (485, 'strange'), (466, 'beautiful'), (459, 'fellow'), (463, 'free'), (464, 'live'), (476, 'forward'), (456, 'business'), (828, 'd'), (463, 'read'), (535, 'several'), (453, 'thousand'), (459, 'deep'), (452, 'drew'), (458, 'run'), (451, 'else'), (461, 'tree'), (447, 'kind'), (458, 'summer'), (444, 'position'), (442, 'ordered'), (1033, 'princess'), (446, 'reason'), (447, 'standing'), (438, 'reached'), (446, 'third'), (2053, 'prince'), (454, 'silence'), (451, 'women'), (443, 'across'), (433, 'grown'), (452, 'bring'), (445, 'strong'), (427, 'doing'), (431, 'human'), (429, 'manner'), (427, 'sight'), (430, 'sitting'), (437, 'chief'), (433, 'heavy'), (448, 'believe'), (459, 'six'), (460, 'immediately'), (426, 'foot'), (421, 'doubt'), (428, 'low'), (428, 'comes'), (419, 'least'), (418, 'expression'), (418, 'person'), (469, 'therefore'), (422, 'truth'), (435, 'friends'), (424, 'thee'), (416, 'wounded'), (415, 'cause'), (413, 'family'), (412, 'meet'), (434, 'sea'), (411, 'tried'), (573, 'perhaps'), (425, 'bad'), (483, 'sir'), (411, 'feel'), (420, 'hard'), (405, 'struck'), (404, 'wished'), (508, 'nature'), (431, 'seeing'), (401, 'strength'), (1470, 'm'), (421, 'pass'), (396, 'sun'), (416, 'call'), (403, 'news'), (401, 'wood'), (396, 'seems'), (415, 'ten'), (389, 'troops'), (388, 'train'), (394, 'sure'), (467, 'thy'), (384, 'stopped'), (420, 'gold'), (383, 'form'), (384, 'moved'), (381, 'enemy'), (383, 'bondes'), (379, 'wind'), (379, 'arrived'), (376, 'closed'), (375, 'soldier'), (377, 'sword'), (374, 'mouth'), (424, 'neither'), (402, 'state'), (373, 'die'), (372, 'means'), (371, 'crowd'), (420, 'sister'), (460, 'although'), (420, 'lady'), (398, 'outside'), (368, 'exclaimed'), (402, 'impossible'), (496, 'countess'), (375, 'answer'), (378, 'service'), (368, 'silent'), (366, 'understood'), (365, 'action'), (364, 'different'), (370, 'leaves'), (367, 'afraid'), (374, 'turning'), (360, 'sides'), (366, 'clear'), (359, 'movement'), (360, 'caught'), (372, 'common'), (358, 'account'), (357, 'knows'), (356, 'shouted'), (359, 'talking'), (370, 'law'), (358, 'presence'), (355, 'waiting'), (360, 'attention'), (354, 'broken'), (379, 'beginning'), (363, 'blue'), (351, 'eye'), (348, 'single'), (351, 'boy'), (352, 'big'), (351, 'remain'), (346, 'rode'), (350, 'hope'), (398, 'remember'), (343, 'steps'), (357, 'usually'), (343, 'covered'), (385, 'doctor'), (341, 'minutes'), (343, 'pale'), (338, 'lips'), (339, 'lived'), (362, 'kings'), (339, 'led'), (336, 'hours'), (342, 'stone'), (338, 'conversation'), (335, 'grow'), (336, 'thinking'), (344, 'according'), (334, 'quickly'), (331, 'desire'), (343, 'show'), (357, 'plant'), (332, 'seized'), (331, 'living'), (327, 'noticed'), (369, 'afterwards'), (334, 'joy'), (333, 'speaking'), (341, 'won'), (357, 'hardly'), (324, 'threw'), (1324, 'yes'), (323, 'coat'), (323, 'grew'), (329, 'makes'), (348, 'police'), (325, 'paper'), (322, 'seem'), (324, 'carriage'), (321, 'duty'), (325, 'age'), (334, 'field'), (321, 'loved'), (338, 'middle'), (324, 'pleasure'), (462, 'north'), (346, 'beneath'), (317, 'neck'), (318, 'glance'), (316, 'latter'), (318, 'sailed'), (319, 'watch'), (338, 'toward'), (321, 'commander'), (313, 'purpose'), (312, 'floor'), (315, 'top'), (309, 'spot'), (309, 'asleep'), (308, 'effect'), (307, 'fallen'), (314, 'follow'), (357, 'master'), (305, 'places'), (305, 'planted'), (304, 'distance'), (309, 'forest'), (305, 'reply'), (330, 'wild'), (304, 'glass'), (307, 'darkness'), (308, 'passing'), (331, 'sons'), (309, 'tears'), (304, 'drawing'), (303, 'eat'), (307, 'except'), (317, 'number'), (299, 'sky'), (304, 'straight'), (300, 'attack'), (298, 'fixed'), (301, 'married'), (308, 'orders'), (297, 'ago'), (307, 'rich'), (304, 'stand'), (297, 'usual'), (298, 'died'), (300, 'dinner'), (301, 'fresh'), (299, 'filled'), (312, 'river'), (297, 'fast'), (299, 'ill'), (294, 'barricade'), (295, 'francs'), (340, 'indeed'), (293, 'fight'), (295, 'officers'), (291, 'allowed'), (299, 'pay'), (295, 'pretty'), (290, 'tone'), (292, 'cry'), (289, 'subject'), (319, 'church'), (480, 'la'), (295, 'thin'), (293, 'evil'), (315, 'nearly'), (287, 'shoulders'), (291, 'step'), (310, 'twenty'), (291, 'houses'), (288, 'box'), (284, 'formed'), (291, 'happiness'), (285, 'anyone'), (289, 'change'), (283, 'listened'), (281, 'bottom'), (282, 'forth'), (300, 'iron'), (285, 'piece'), (281, 'appearance'), (284, 'faces'), (310, 'history'), (287, 'kingdom'), (285, 'thoughts'), (345, 'wait'), (279, 'direction'), (281, 'handsome'), (279, 'replies'), (279, 'village'), (289, 'enter'), (281, 'former'), (278, 'mean'), (278, 'repeated'), (278, 'week'), (303, 'beyond'), (280, 'danger'), (275, 'instant'), (277, 'lying'), (313, 'none'), (277, 'particularly'), (278, 'smoke'), (275, 'trouble'), (275, 'walked'), (289, 'green'), (276, 'regiment'), (310, 'society'), (343, 'certainly'), (297, 'company'), (283, 'kill'), (271, 'merely'), (271, 'proceeded'), (271, 'bit'), (284, 'mass'), (277, 'bear'), (272, 'further'), (270, 'prepared'), (293, 'seven'), (296, 'journey'), (272, 'leaving'), (272, 'walk'), (266, 'bent'), (269, 'snow'), (266, 'wide'), (280, 'try'), (269, 'view'), (269, 'growing'), (265, 'holding'), (263, 'resumed'), (263, 'smiled'), (275, 'story'), (264, 'dry'), (265, 'getting'), (263, 'angry'), (260, 'appear'), (260, 'kinds'), (259, 'ourselves'), (273, 'apart'), (265, 'ought'), (263, 'roots'), (260, 'showed'), (268, 'begin'), (257, 'important'), (258, 'legs'), (256, 'simple'), (258, 'cast'), (256, 'effort'), (255, 'started'), (262, 'carry'), (260, 'especially'), (274, 'below'), (274, 'castle'), (256, 'fled'), (253, 'clothes'), (251, 'paid'), (254, 'heads'), (256, 'running'), (253, 'drawn'), (250, 'seated'), (253, 'slowly'), (265, 'varieties'), (251, 'events'), (248, 'hat'), (247, 'opinion'), (248, 'pleased'), (250, 'trying'), (246, 'caused'), (251, 'drove'), (248, 'expected'), (249, 'escape'), (247, 'giving'), (244, 'chair'), (244, 'months'), (267, 'probably'), (248, 'victory'), (249, 'glad'), (244, 'greater'), (255, 'seed'), (243, 'easy'), (256, 'meeting'), (245, 'real'), (243, 'smiling'), (360, 'south'), (244, 'letters'), (262, 'sweet'), (269, 'yellow'), (245, 'bright'), (254, 'chance'), (241, 'difficult'), (240, 'inches'), (243, 'wine'), (239, 'pocket'), (242, 'warm'), (241, 'written'), (245, 'post'), (239, 'serious'), (240, 'simply'), (240, 'teeth'), (239, 'wrong'), (242, 'act'), (237, 'condition'), (278, 'everyone'), (237, 'gazed'), (280, 'le'), (238, 'lines'), (238, 'quarter'), (249, 'various'), (238, 'voices'), (238, 'sad'), (242, 'study'), (280, 'court'), (234, 'disappeared'), (238, 'drink'), (236, 'laugh'), (257, 'brothers'), (231, 'ft'), (271, 'please'), (232, 'shown'), (232, 'spite'), (231, 'bound'), (252, 'city'), (232, 'finished'), (231, 'habit'), (231, 'plain'), (236, 'public'), (230, 'remarked'), (230, 'broke'), (229, 'interest'), (229, 'command'), (230, 'dressed'), (230, 'goes'), (233, 'questions'), (231, 'rain'), (228, 'considered'), (240, 'tall'), (227, 'frightened'), (228, 'future'), (229, 'moving'), (230, 'streets'), (228, 'weather'), (279, 'whatever'), (243, 'excellent'), (226, 'forms'), (225, 'parts'), (262, 'art'), (233, 'save'), (228, 'space'), (230, 'lie'), (246, 'brave'), (236, 'eight'), (226, 'gentleman'), (229, 'unknown'), (222, 'breath'), (224, 'lies'), (222, 'thrown'), (310, 'book'), (221, 'settled'), (222, 'touched'), (221, 'girls'), (221, 'grave'), (219, 'minute'), (233, 'bridge'), (219, 'deal'), (220, 'move'), (222, 'surprise'), (220, 'wolf'), (217, 'advanced'), (222, 'contrary'), (220, 'dress'), (217, 'affair'), (216, 'changed'), (218, 'flew'), (217, 'hole'), (219, 'looks'), (233, 'send'), (215, 'talked'), (229, 'allow'), (216, 'aside'), (225, 'blow'), (222, 'calm'), (233, 'honor'), (219, 'plan'), (213, 'remembered'), (217, 'sign'), (236, 'sit'), (215, 'spread'), (223, 'dream'), (212, 'month'), (216, 'planting'), (224, 'speech'), (213, 'surface'), (214, 'affairs'), (213, 'season'), (217, 'shadow'), (216, 'dog'), (211, 'walls'), (209, 'glanced'), (218, 'lower'), (210, 'matters'), (210, 'occupied'), (209, 'offered'), (212, 'play'), (209, 'presented'), (211, 'result'), (210, 'understanding'), (217, 'hall'), (213, 'peasant'), (209, 'property'), (208, 'sprang'), (226, 'stay'), (209, 'easily'), (220, 'flight'), (216, 'knowing'), (207, 'laughed'), (211, 'shot'), (209, 'bread'), (209, 'sown'), (207, 'burst'), (211, 'gate'), (208, 'rushed'), (205, 'spoken'), (203, 'desired'), (204, 'forced'), (207, 'pity'), (206, 'burning'), (216, 'station'), (202, 'wrote'), (204, 'crime'), (201, 'windows'), (364, 'besides'), (202, 'rapidly'), (202, 'seat'), (205, 'secret'), (203, 'terror'), (200, 'appears'), (200, 'laughing'), (199, 'sense'), (230, 'to-day'), (210, 'youth'), (198, 'greatest'), (203, 'message'), (198, 'occurred'), (198, 'perceived'), (215, 'quick'), (198, 'shook'), (203, 'start'), (205, 'bird'), (197, 'knees'), (198, 'papers'), (199, 'quiet'), (197, 'removed'), (199, 'special'), (200, 'advance'), (197, 'begun'), (198, 'empty'), (200, 'fly'), (214, 'marriage'), (209, 'shut'), (209, 'twelve'), (197, 'visible'), (212, 'write'), (202, 'board'), (288, 'east'), (199, 'respect'), (195, 'sake'), (196, 'dying'), (213, 'everywhere'), (231, 'figure'), (197, 'fleet'), (234, 'heaven'), (195, 'perfectly'), (193, 'recognized'), (196, 'silver'), (198, 'break'), (244, 'cross'), (198, 'farther'), (194, 'grass'), (198, 'spirit'), (192, 'waited'), (194, 'immense'), (193, 'observed'), (190, 'gathered'), (252, 'listen'), (191, 'promised'), (205, 'trench'), (191, 'difficulty'), (205, 'fate'), (196, 'useful'), (199, 'foliage'), (188, 'kissed'), (188, 'length'), (189, 'noise'), (188, 'relations'), (188, 'required'), (225, 'stop'), (220, 'thick'), (189, 'ball'), (187, 'moments'), (197, 'ring'), (197, 'thirty'), (186, 'approached'), (186, 'happen'), (186, 'paused'), (186, 'pointed'), (186, 'related'), (186, 'served'), (187, 'shoulder'), (192, 'tender'), (189, 'forces'), (187, 'lives'), (189, 'priest'), (193, 'beauty'), (184, 'ears'), (184, 'experienced'), (188, 'midst'), (194, 'persons'), (184, 'bloom'), (192, 'charming'), (184, 'ended'), (183, 'hot'), (187, 'inside'), (184, 'occasion'), (183, 'ones'), (187, 'opening'), (185, 'pressed'), (191, 'prisoner'), (195, 'search'), (192, 'ancient'), (184, 'natural'), (183, 'object'), (182, 'reach'), (182, 'bare'), (182, 'doors'), (181, 'fit'), (240, 'guard'), (207, 'instead'), (197, 'justice'), (183, 'proper'), (182, 'stones'), (183, 'visit'), (186, 'agreed'), (189, 'becomes'), (186, 'feast'), (180, 'gloomy'), (183, 'marry'), (182, 'prevent'), (180, 'produced'), (185, 'worse'), (180, 'worth'), (185, 'clearly'), (182, 'enormous'), (180, 'friendship'), (180, 'notice'), (179, 'slept'), (180, 'walking'), (180, 'wound'), (178, 'bore'), (180, 'falling'), (180, 'particular'), (192, 'someone'), (178, 'species'), (207, 'yard'), (178, 'cap'), (262, 'march'), (179, 'melancholy'), (181, 'mysterious'), (180, 'pain'), (180, 'suffering'), (176, 'gentle'), (201, 'hill'), (176, 'knife'), (177, 'nose'), (180, 'regard'), (181, 'adjutant'), (178, 'food'), (180, 'forget'), (176, 'group'), (175, 'inquired'), (317, 'l'), (176, 'prisoners'), (212, 'ye'), (174, 'ceased'), (183, 'chamber'), (234, 'holy'), (190, 'military'), (175, 'race'), (176, 'report'), (174, 'rows'), (178, 'sharp'), (178, 'weeks'), (176, 'advice'), (173, 'evident'), (177, 'mine'), (173, 'rule'), (178, 'broad'), (173, 'composed'), (174, 'ideas'), (172, 'likely'), (172, 'meaning'), (172, 'memory'), (184, 'note'), (203, 'to-morrow'), (171, 'alive'), (185, 'amid'), (172, 'asking'), (173, 'complete'), (175, 'entirely'), (171, 'fingers'), (172, 'learned'), (174, 'shadows'), (171, 'throat'), (209, 'golden'), (172, 'growth'), (177, 'imagine'), (178, 'ladies'), (171, 'lifted'), (170, 'meant'), (171, 'unable'), (170, 'uttered'), (169, 'breast'), (173, 'horror'), (169, 'motionless'), (173, 'generally'), (168, 'guns'), (173, 'haste'), (170, 'key'), (173, 'laws'), (177, 'opposite'), (168, 'party'), (173, 'straw'), (170, 'becoming'), (169, 'candle'), (167, 'character'), (167, 'decided'), (179, 'fifteen'), (167, 'obliged'), (168, 'surprised'), (168, 'touch'), (170, 'autumn'), (239, 'captain'), (170, 'freedom'), (170, 'passage'), (175, 'staff'), (167, 'telling'), (165, 'belonged'), (166, 'branches'), (168, 'carefully'), (187, 'formerly'), (164, 'arranged'), (166, 'conditions'), (166, 'lose'), (164, 'mentioned'), (166, 'reader'), (168, 'satisfied'), (169, 'stout'), (163, 'advantage'), (170, 'despair'), (188, 'everybody'), (165, 'express'), (170, 'fruit'), (163, 'pulled'), (172, 'suppose'), (167, 'takes'), (163, 'vessel'), (163, 'concealed'), (167, 'departure'), (167, 'district'), (162, 'finger'), (162, 'interrupted'), (172, 'throw'), (161, 'crop'), (161, 'crossed'), (164, 'des'), (166, 'drive'), (166, 'entering'), (162, 'forgotten'), (162, 'quarters'), (163, 'buried'), (161, 'frightful'), (165, 'receive'), (160, 'shore'), (160, 'spent'), (160, 'sufficient'), (166, 'absolutely'), (162, 'er'), (159, 'lighted'), (163, 'rise'), (163, 'boots'), (175, 'devil'), (158, 'expressed'), (167, 'fair'), (158, 'fault'), (158, 'handed'), (160, 'loss'), (160, 'manure'), (160, 'narrow'), (158, 'path'), (160, 'peasants'), (158, 'sought'), (158, 'sudden'), (158, 'built'), (163, 'double'), (159, 'gray'), (163, 'health'), (163, 'huge'), (157, 'liked'), (159, 'mud'), (157, 'edge'), (225, 'grand'), (156, 'joined'), (157, 'possession'), (158, 'profound'), (155, 'beheld'), (209, 'colonel'), (158, 'grandfather'), (160, 'row'), (157, 'saved'), (160, 'seek'), (155, 'sorts'), (156, 'stupid'), (161, 'du'), (156, 'false'), (157, 'fashion'), (158, 'firm'), (154, 'fought'), (155, 'knowledge'), (160, 'lead'), (154, 'pieces'), (164, 'social'), (156, 'thrust'), (154, 'watched'), (154, 'wore'), (168, 'building'), (154, 'chiefs'), (167, 'clever'), (193, 'consider'), (155, 'depths'), (156, 'faith'), (153, 'intended'), (154, 'luck'), (154, 'putting'), (192, 'square'), (153, 'weak'), (153, 'whispered'), (155, 'escaped'), (152, 'event'), (162, 'flat'), (153, 'mad'), (174, 'murder'), (157, 'nearer'), (153, 'pushed'), (154, 'remains'), (153, 'stranger'), (152, 'uniform'), (155, 'beds'), (158, 'fortune'), (174, 'government'), (156, 'hearing'), (173, 'progress'), (153, 'rooms'), (150, 'appointed'), (150, 'boxes'), (150, 'dropped'), (151, 'lawn'), (162, 'liberty'), (153, 'merry'), (157, 'promise'), (150, 'shouting'), (153, 'surrounded'), (150, 'borne'), (151, 'driver'), (150, 'existence'), (151, 'facts'), (150, 'gesture'), (152, 'hung'), (149, 'needed'), (149, 'peculiar'), (149, 'quietly'), (157, 'song'), (150, 'succeeded'), (149, 'thoroughly'), (149, 'vague'), (149, 'aim'), (155, 'cat'), (148, 'explain'), (160, 'kindly'), (148, 'necessity'), (148, 'proved'), (149, 'worthy'), (149, 'confused'), (251, 'queen'), (147, 'rising'), (147, 'roof'), (151, 'somewhat'), (148, 'vast'), (148, 'address'), (146, 'addressed'), (147, 'cart'), (146, 'explained'), (146, 'gained'), (146, 'horrible'), (161, 'sewer'), (175, 'yesterday'), (147, 'cannon'), (145, 'creature'), (145, 'expect'), (148, 'laughter'), (146, 'powerful'), (159, 'reading'), (149, 'souls'), (146, 'century'), (149, 'loud'), (144, 'sang'), (145, 'servants'), (167, 'twice'), (144, 'accompanied'), (145, 'armed'), (143, 'bench'), (154, 'fifty'), (144, 'gazing'), (145, 'keeping'), (147, 'listening'), (146, 'passion'), (144, 'results'), (149, 'severe'), (142, 'assembled'), (162, 'blind'), (149, 'bold'), (142, 'coffin'), (143, 'offer'), (142, 'safe'), (155, 'seeds'), (142, 'shock'), (143, 'soft'), (157, 'unless'), (142, 'fields'), (143, 'mingled'), (141, 'possessed'), (141, 'servant'), (142, 'clouds'), (155, 'didn'), (141, 'lad'), (141, 'leg'), (140, 'lot'), (140, 'named'), (143, 'pleasant'), (140, 'stepped'), (143, 'arrival'), (140, 'badly'), (140, 'carrying'), (141, 'cases'), (139, 'determined'), (161, 'hardy'), (151, 'otherwise'), (141, 'situation'), (139, 'treated'), (140, 'accept'), (138, 'cloak'), (139, 'conscious'), (156, 'convent'), (150, 'cover'), (139, 'dust'), (139, 'ordinary'), (138, 'picked'), (139, 'ranks'), (138, 'relation'), (138, 'shoes'), (139, 'wheels'), (138, 'bowed'), (140, 'conscience'), (138, 'names'), (137, 'played'), (138, 'violent'), (137, 'watching'), (137, 'circumstances'), (145, 'draw'), (138, 'experience'), (136, 'friendly'), (137, 'greatly'), (136, 'singing'), (143, 'success'), (139, 'birds'), (152, 'courage'), (138, 'deserted'), (135, 'ear'), (136, 'harm'), (143, 'nine'), (135, 'paces'), (138, 'splendid'), (137, 'trembling'), (134, 'aid'), (136, 'brilliant'), (138, 'daylight'), (134, 'distant'), (135, 'engine'), (138, 'equal'), (139, 'gently'), (136, 'maid'), (135, 'raise'), (138, 'returning'), (136, 'setting'), (141, 'somewhere'), (136, 'sorry'), (134, 'suffer'), (139, 'wet'), (133, 'activity'), (137, 'border'), (139, 'catch'), (138, 'dare'), (133, 'engaged'), (158, 'expedition'), (134, 'increased'), (139, 'learn'), (154, 'nobody'), (135, 'prove'), (136, 'sounds'), (133, 'suffered'), (137, 'supper'), (145, 'to-night'), (133, 'ways'), (132, 'due'), (134, 'dull'), (154, 'gentlemen'), (138, 'loose'), (132, 'retreat'), (138, 'sand'), (133, 'summoned'), (131, 'fully'), (134, 'gives'), (132, 'points'), (134, 'trust'), (152, 'add'), (134, 'admit'), (130, 'cloth'), (130, 'dared'), (178, 'dwarf'), (132, 'gaze'), (131, 'serve'), (130, 'size'), (130, 'tongue'), (129, 'actions'), (130, 'anxious'), (130, 'cloud'), (130, 'couple'), (129, 'demanded'), (129, 'details'), (129, 'directed'), (129, 'happens'), (129, 'opportunity'), (129, 'refused'), (130, 'writing'), (128, 'beings'), (132, 'campaign'), (133, 'dawn'), (128, 'ease'), (146, 'exactly'), (131, 'glory'), (128, 'main'), (128, 'recognize'), (129, 'sick'), (128, 'abandoned'), (128, 'circle'), (127, 'distinguished'), (132, 'extraordinary'), (127, 'fond'), (130, 'higher'), (128, 'level'), (127, 'shade'), (128, 'sous'), (126, 'approaching'), (425, 'bishop'), (127, 'books'), (126, 'brain'), (126, 'cellar'), (126, 'chest'), (128, 'chosen'), (127, 'completely'), (127, 'dreadful'), (129, 'driven'), (131, 'excellency'), (127, 'flesh'), (126, 'galleys'), (126, 'gun'), (126, 'murmured'), (128, 'singular'), (126, 'slight'), (129, 'anger'), (128, 'familiar'), (125, 'halted'), (126, 'historians'), (127, 'regular'), (125, 'separated'), (125, 'sleeping'), (127, 'storm'), (125, 'vessels'), (159, 'finally'), (125, 'heat'), (125, 'hideous'), (126, 'honest'), (124, 'protection'), (138, 'roses'), (134, 'skald'), (123, 'accepted'), (124, 'anxiety'), (123, 'corpse'), (134, 'farm'), (125, 'grief'), (128, 'height'), (132, 'misery'), (128, 'shield'), (126, 'stands'), (123, 'task'), (125, 'torn'), (124, 'cavalry'), (124, 'counsel'), (122, 'feared'), (122, 'forehead'), (122, 'gloom'), (123, 'heap'), (126, 'honour'), (123, 'material'), (126, 'perfect'), (126, 'private'), (123, 'sail'), (138, 'whence'), (127, 'directly'), (122, 'firing'), (127, 'flower'), (124, 'noble'), (125, 'office'), (124, 'personal'), (122, 'remark'), (205, 'west'), (130, 'avoid'), (121, 'believed'), (126, 'bow'), (135, 'bulbs'), (122, 'charge'), (122, 'cleared'), (124, 'drop'), (128, 'fourth'), (123, 'goods'), (131, 'instantly'), (121, 'pair'), (120, 'shed'), (122, 'speed'), (121, 'stretched'), (121, 'tired'), (123, 'virtue'), (120, 'cheeks'), (120, 'destroyed'), (119, 'direct'), (120, 'entrance'), (120, 'prison'), (123, 'pure'), (119, 'rage'), (120, 'resolved'), (123, 'wedding'), (125, 'wonderful'), (124, 'absolute'), (119, 'attitude'), (120, 'beast'), (118, 'dangerous'), (120, 'deeply'), (118, 'descended'), (123, 'dogs'), (118, 'established'), (123, 'finding'), (119, 'gay'), (118, 'masses'), (119, 'merchant'), (174, 'pray'), (120, 'sorrow'), (120, 'vain'), (117, 'begged'), (119, 'comrades'), (122, 'cutting'), (117, 'discovered'), (117, 'examined'), (118, 'join'), (121, 'leading'), (117, 'pause'), (119, 'shows'), (118, 'support'), (117, 'turns'), (119, 'wants'), (119, 'wearing'), (117, 'accustomed'), (118, 'continually'), (116, 'existed'), (123, 'hast'), (116, 'method'), (146, 'whilst'), (117, 'beat'), (121, 'choose'), (115, 'corridor'), (120, 'glancing'), (128, 'kiss'), (116, 'lit'), (117, 'nice'), (116, 'porter'), (116, 'rapid'), (129, 'royal'), (115, 'value'), (115, 'vanished'), (114, 'animal'), (116, 'curiosity'), (117, 'fighting'), (117, 'generals'), (114, 'hurt'), (114, 'oath'), (117, 'rear'), (114, 'stared'), (118, 'stars'), (116, 'cook'), (113, 'guests'), (114, 'hanging'), (115, 'hastily'), (113, 'importance'), (143, 'isn'), (113, 'jumped'), (114, 'miles'), (114, 'mist'), (115, 'pointing'), (115, 'scene'), (113, 'stayed'), (117, 'tea'), (130, 'tomorrow'), (113, 'variety'), (113, 'wooden'), (115, 'worn'), (113, 'attacked'), (114, 'bodies'), (113, 'breathing'), (114, 'center'), (113, 'committed'), (115, 'dirty'), (117, 'frequently'), (113, 'highest'), (156, 'mon'), (130, 'scarcely'), (113, 'sees'), (115, 'slightly'), (112, 'sum'), (114, 'unhappy'), (137, 'bank'), (111, 'brow'), (112, 'bushes'), (112, 'depth'), (113, 'difference'), (111, 'dignity'), (111, 'hastened'), (111, 'hidden'), (118, 'hurry'), (113, 'moon'), (111, 'playing'), (111, 'porch'), (112, 'tells'), (114, 'upper'), (112, 'weary'), (110, 'approach'), (112, 'attempt'), (111, 'causes'), (111, 'convinced'), (111, 'epoch'), (110, 'mistake'), (110, 'resolution'), (110, 'rope'), (113, 'similar'), (110, 'skin'), (115, 'thence'), (111, 'troubled'), (110, 'weapons'), (110, 'confidence'), (114, 'desirable'), (111, 'game'), (113, 'infantry'), (109, 'innocent'), (112, 'lendermen'), (110, 'linen'), (109, 'muttered'), (109, 'sofa'), (110, 'burned'), (108, 'convict'), (108, 'declared'), (110, 'drunk'), (108, 'entire'), (109, 'exist'), (110, 'influence'), (109, 'lamp'), (108, 'movements'), (108, 'previous'), (115, 'proceed'), (108, 'rendered'), (112, 'thither'), (107, 'ate'), (107, 'aware'), (107, 'boat'), (115, 'clean'), (119, 'fancy'), (107, 'flank'), (107, 'gain'), (110, 'hussars'), (107, 'hut'), (109, 'popular'), (111, 'agreement'), (107, 'awoke'), (107, 'band'), (106, 'branch'), (107, 'collected'), (107, 'conceal'), (107, 'confusion'), (107, 'frame'), (106, 'galloped'), (177, 'hills'), (106, 'impression'), (106, 'pavement'), (106, 'produce'), (111, 'raising'), (111, 'shouts'), (105, 'attached'), (109, 'beard'), (106, 'beg'), (106, 'blame'), (105, 'closely'), (106, 'driving'), (105, 'example'), (106, 'flame'), (106, 'frost'), (116, 'meantime'), (105, 'pipe'), (105, 'rolled'), (108, 'sacrifice'), (106, 'share'), (106, 'shining'), (106, 'terrified'), (112, 'tomb'), (117, 'yours'), (105, 'breaking'), (106, 'defend'), (105, 'delicate'), (105, 'eastward'), (112, 'erect'), (116, 'forty'), (106, 'hollow'), (105, 'interesting'), (105, 'larger'), (105, 'mere'), (107, 'mystery'), (110, 'provided'), (104, 'satisfaction'), (104, 'shudder'), (109, 'abruptly'), (104, 'absence'), (104, 'aloud'), (103, 'angrily'), (103, 'bearing'), (111, 'born'), (104, 'busy'), (103, 'companion'), (103, 'connection'), (103, 'covering'), (105, 'cries'), (103, 'disease'), (108, 'divine'), (104, 'intelligence'), (107, 'judge'), (105, 'leaning'), (104, 'pots'), (103, 'reality'), (103, 'remaining'), (105, 'slow'), (106, 'artillery'), (102, 'assistant'), (105, 'bell'), (105, 'carriages'), (104, 'coast'), (106, 'curious'), (104, 'fatigue'), (102, 'freely'), (103, 'hearts'), (103, 'kitchen'), (102, 'managed'), (103, 'reasons'), (103, 'ride'), (102, 'ruled'), (102, 'silently'), (112, 'sovereign'), (102, 'struggle'), (142, 'thanks'), (108, 'universal'), (112, 'wise'), (105, 'begins'), (102, 'considerable'), (106, 'destiny'), (101, 'distinctly'), (101, 'formidable'), (103, 'gardener'), (110, 'grey'), (109, 'inn'), (101, 'locked'), (114, 'nonsense'), (101, 'plunged'), (104, 'showing'), (101, 'smell'), (102, 'useless'), (101, 'worked'), (101, 'absorbed'), (100, 'agree'), (102, 'astonished'), (101, 'authority'), (105, 'bourgeois'), (101, 'chain'), (102, 'crossing'), (101, 'divided'), (100, 'eaten'), (116, 'elder'), (101, 'ends'), (108, 'gradually'), (102, 'instinct'), (100, 'mounted'), (100, 'pistol'), (102, 'pot'), (103, 'pride'), (100, 'slipped'), (100, 'station-master'), (182, 'thank'), (100, 'wounds'), (22996, 'i')]\n"
     ]
    }
   ],
   "source": [
    "lines_books_train = read_files('./inf265_v24_project03_data/data_train/')\n",
    "lines_books_val = read_files('./inf265_v24_project03_data/data_val/')\n",
    "lines_books_test = read_files('./inf265_v24_project03_data/data_test/')\n",
    "\n",
    "# List of words contained in the dataset\n",
    "words_train = tokenize(lines_books_train)\n",
    "words_val = tokenize(lines_books_val)\n",
    "words_test = tokenize(lines_books_test)\n",
    "\n",
    "\n",
    "vocab = create_vocabulary(lines_books_train, min_freq=100)\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "\n",
    "print(\"Total number of words in the training dataset:     \", len(words_train))\n",
    "print(\"Total number of words in the validation dataset:   \", len(words_val))\n",
    "print(\"Total number of words in the test dataset:         \", len(words_test))\n",
    "print(\"Number of distinct words in the training dataset:  \", len(set(words_train)))\n",
    "print(\"Number of distinct words kept (vocabulary size):   \", VOCAB_SIZE)\n",
    "\n",
    "freqs = count_freqs(words_train, vocab)\n",
    "print(\"occurences:\\n\", [(f.item(), w) for (f, w)  in zip(freqs, vocab.lookup_tokens(range(VOCAB_SIZE)))])    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on result:\n",
    "The total number of words in the trainingset is a lot with 2 684 706 words. However the number goes down drasticaly when we limit it to distinct words in the trainingset and we can even narrow it down more to a vocabuary size of only 1880 when we limit words that occur over 100 times. \n",
    "The most common words in the text is special characters like \",\" and \".\"\n",
    "\n",
    "If we look away from those special characters we see that the most common words are expected commonly used words like \"the\", \"and\", \"of\", \"to\" etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a continuous bag of words model architecture based on this vocabulary that contains\n",
    "an embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):        \n",
    "        embeddings = self.embeddings(inputs)\n",
    "        embeddings = torch.sum(embeddings, dim=1)        \n",
    "        out = self.linear(embeddings)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the training function, accuracy function and a function to create context target pairs so that we have data to train on. We use a context size of 3 in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text, vocab, context_size=3):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataset of context / target pairs from a text\n",
    "    \"\"\"\n",
    "    n_text = len(text)\n",
    "    \n",
    "    # Transform the text as a list of integers.\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    # Start constructing the context / target pairs.\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size):\n",
    "        # Word used to define target\n",
    "        t = txt[i + context_size]\n",
    "        # Context before the target\n",
    "        c = txt[i:i + context_size]\n",
    "        targets.append(t)\n",
    "        contexts.append(torch.tensor(c))\n",
    "            \n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    return TensorDataset(contexts, targets)\n",
    "\n",
    "\n",
    "\n",
    "def train(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        loss_train = 0.0\n",
    "        for contexts, targets in train_loader:\n",
    "\n",
    "            contexts = contexts.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            outputs = model(contexts)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "        if epoch == 1 or epoch % 2 == 0 or epoch == n_epochs:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.5f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))            \n",
    "    #return losses_train\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for contexts, targets in loader:\n",
    "            contexts = contexts.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            outputs = model(contexts)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += len(targets)\n",
    "            correct += int((predicted == targets).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training several models and picking best based on validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with bach size: 32, and learning rate: 0.1 \n",
      "17:06:18.713324  |  Epoch 1  |  Training loss 7.67768\n",
      "17:08:05.932954  |  Epoch 2  |  Training loss 7.71238\n",
      "17:11:38.352978  |  Epoch 4  |  Training loss 7.71309\n",
      "17:13:25.239821  |  Epoch 5  |  Training loss 7.71305\n",
      "Model: validation accuracy:0.08448599640571047\n",
      "Training model with bach size: 32, and learning rate: 0.01 \n",
      "17:15:12.755205  |  Epoch 1  |  Training loss 4.61213\n",
      "17:17:00.654419  |  Epoch 2  |  Training loss 4.58096\n",
      "17:20:33.026902  |  Epoch 4  |  Training loss 4.57998\n",
      "17:22:16.943694  |  Epoch 5  |  Training loss 4.57978\n",
      "Model: validation accuracy:0.1690123780869495\n",
      "Training model with bach size: 64, and learning rate: 0.1 \n",
      "17:23:18.041192  |  Epoch 1  |  Training loss 6.12135\n",
      "17:24:17.974190  |  Epoch 2  |  Training loss 6.12672\n",
      "17:26:18.167468  |  Epoch 4  |  Training loss 6.12640\n",
      "17:27:19.263966  |  Epoch 5  |  Training loss 6.12749\n",
      "Model: validation accuracy:0.10740464026815823\n",
      "Training model with bach size: 64, and learning rate: 0.01 \n",
      "17:28:20.233355  |  Epoch 1  |  Training loss 4.56534\n",
      "17:29:19.618882  |  Epoch 2  |  Training loss 4.52001\n",
      "17:31:18.063157  |  Epoch 4  |  Training loss 4.51858\n",
      "17:32:18.563642  |  Epoch 5  |  Training loss 4.51788\n",
      "Model: validation accuracy:0.17052682591926985\n",
      "Final best model is a model with bach size: 64, and learning rate: 0.01 \n",
      "\n",
      "Best model: validation accuracy: 17.05%\n"
     ]
    }
   ],
   "source": [
    "# context size for this project\n",
    "CONTEXT_SIZE = 3\n",
    "train_data = create_dataset(words_train, vocab, context_size=CONTEXT_SIZE)\n",
    "val_data = create_dataset(words_val, vocab, context_size=CONTEXT_SIZE)\n",
    "test_data = create_dataset(words_test, vocab, context_size=CONTEXT_SIZE)\n",
    "\n",
    "#Validation dataloader\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True)\n",
    "\n",
    "#Global params\n",
    "n_epochs = 5\n",
    "loss_fn = nn.NLLLoss() \n",
    "\n",
    "\n",
    "#Hyperparams\n",
    "batch_size = [32, 64]\n",
    "lr_list = [0.1, 0.01]\n",
    "\n",
    "#Initial best params\n",
    "best_model = None\n",
    "best_batch = 0\n",
    "best_lr = 0\n",
    "best_v_acc = 0\n",
    "\n",
    "#Model selection\n",
    "for bs in batch_size:\n",
    "    for lr in lr_list:\n",
    "        print(f\"Training model with bach size: {bs}, and learning rate: {lr} \")\n",
    "        model = CBOW(embedding_dim = 16, vocab_size=VOCAB_SIZE).to(device=device) \n",
    "        train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "        #Train\n",
    "        net_weights = train(n_epochs=n_epochs, optimizer=optimizer, model=model, loss_fn=loss_fn, train_loader=train_loader)\n",
    "        #Compute Validation acc\n",
    "        val_acc = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "        print(f\"Model: validation accuracy:{val_acc}\")\n",
    "        if val_acc > best_v_acc:\n",
    "            best_batch = bs\n",
    "            best_lr = lr\n",
    "            best_v_acc = val_acc\n",
    "            best_model = model\n",
    "\n",
    "\n",
    "print(f\"Final best model is a model with bach size: {best_batch}, and learning rate: {best_lr} \")\n",
    "print()\n",
    "print(f\"Best model: validation accuracy: {best_v_acc:.2%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbiased estimate using test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of best model 21.14%\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "tes_accuracy = compute_accuracy(best_model, test_loader, device=device)\n",
    "print(f\"Test accuracy of best model {tes_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Compute cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'me':\n",
      "  Nr. 1: me\n",
      "  Nr. 2: yourself\n",
      "  Nr. 3: die\n",
      "  Nr. 4: ourselves\n",
      "  Nr. 5: us\n",
      "  Nr. 6: himself\n",
      "  Nr. 7: myself\n",
      "  Nr. 8: to-night\n",
      "  Nr. 9: mine\n",
      "  Nr. 10: him\n",
      "  Nr. 11: matters\n",
      "Words most similar to 'white':\n",
      "  Nr. 1: white\n",
      "  Nr. 2: thin\n",
      "  Nr. 3: red\n",
      "  Nr. 4: deep\n",
      "  Nr. 5: bright\n",
      "  Nr. 6: blue\n",
      "  Nr. 7: grey\n",
      "  Nr. 8: bare\n",
      "  Nr. 9: green\n",
      "  Nr. 10: large\n",
      "  Nr. 11: black\n",
      "Words most similar to 'man':\n",
      "  Nr. 1: man\n",
      "  Nr. 2: child\n",
      "  Nr. 3: girl\n",
      "  Nr. 4: dog\n",
      "  Nr. 5: woman\n",
      "  Nr. 6: doctor\n",
      "  Nr. 7: officer\n",
      "  Nr. 8: bondes\n",
      "  Nr. 9: person\n",
      "  Nr. 10: mother\n",
      "  Nr. 11: enemy\n",
      "Words most similar to 'have':\n",
      "  Nr. 1: have\n",
      "  Nr. 2: has\n",
      "  Nr. 3: ve\n",
      "  Nr. 4: nearly\n",
      "  Nr. 5: had\n",
      "  Nr. 6: having\n",
      "  Nr. 7: hast\n",
      "  Nr. 8: produce\n",
      "  Nr. 9: give\n",
      "  Nr. 10: paid\n",
      "  Nr. 11: make\n",
      "Words most similar to 'be':\n",
      "  Nr. 1: be\n",
      "  Nr. 2: being\n",
      "  Nr. 3: art\n",
      "  Nr. 4: been\n",
      "  Nr. 5: were\n",
      "  Nr. 6: remain\n",
      "  Nr. 7: names\n",
      "  Nr. 8: nearly\n",
      "  Nr. 9: died\n",
      "  Nr. 10: commander\n",
      "  Nr. 11: sleep\n",
      "Words most similar to 'child':\n",
      "  Nr. 1: child\n",
      "  Nr. 2: doctor\n",
      "  Nr. 3: man\n",
      "  Nr. 4: woman\n",
      "  Nr. 5: officer\n",
      "  Nr. 6: girl\n",
      "  Nr. 7: gun\n",
      "  Nr. 8: boy\n",
      "  Nr. 9: gentleman\n",
      "  Nr. 10: lady\n",
      "  Nr. 11: bishop\n",
      "Words most similar to 'yes':\n",
      "  Nr. 1: yes\n",
      "  Nr. 2: sir\n",
      "  Nr. 3: excellency\n",
      "  Nr. 4: drink\n",
      "  Nr. 5: please\n",
      "  Nr. 6: justice\n",
      "  Nr. 7: matters\n",
      "  Nr. 8: cry\n",
      "  Nr. 9: cried\n",
      "  Nr. 10: hurry\n",
      "  Nr. 11: gardener\n",
      "Words most similar to 'what':\n",
      "  Nr. 1: what\n",
      "  Nr. 2: whatever\n",
      "  Nr. 3: how\n",
      "  Nr. 4: although\n",
      "  Nr. 5: that\n",
      "  Nr. 6: if\n",
      "  Nr. 7: whom\n",
      "  Nr. 8: whether\n",
      "  Nr. 9: since\n",
      "  Nr. 10: because\n",
      "  Nr. 11: why\n"
     ]
    }
   ],
   "source": [
    "net_emb_w = best_model.embeddings.weight.data\n",
    "normalized_embeddings = F.normalize(net_emb_w)\n",
    "\n",
    "#Cosine similarity matrix\n",
    "cosine_similarity_matrix = torch.mm(normalized_embeddings, normalized_embeddings.transpose(0, 1))\n",
    "words_to_check = ['me', 'white', 'man', 'have', 'be', 'child', 'yes', 'what']\n",
    "word_indices = [vocab.get_stoi()[word] for word in words_to_check if word in vocab.get_stoi()]\n",
    "top = 10\n",
    "most_similar_words = {}\n",
    "\n",
    "for index in word_indices:\n",
    "    similarities = cosine_similarity_matrix[index]\n",
    "    top_indices = torch.topk(similarities, top + 1).indices\n",
    "    similar_words = [vocab.get_itos()[i] for i in top_indices]\n",
    "    most_similar_words[vocab.get_itos()[index]] = similar_words\n",
    "\n",
    "\n",
    "for word, similar_words in most_similar_words.items():\n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    for rank, similar_word in enumerate(similar_words, 1):\n",
    "        print(f\"  Nr. {rank}: {similar_word}\")    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the words seem to be similar, for example with the word 'child' only 'boy' and 'girl' seems to be words with similar meaning. This is probably a consequence of our small embedding dimension size, however we still get some similar words.\n",
    "Like for example the most similar words to 'have' (has, ve, nearly, had, having, hast) or 'what' (what, whatever, how, although) shows very similar words. This shows that our embedding space does manage to show patterns of similarity.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Visualize the embedding space on https://projector.tensorflow.org/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./embedding.tsv\", \"wt\") as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter=\"\\t\")\n",
    "    for i in net_emb_w:\n",
    "        tsv_writer.writerow(i.cpu().numpy())\n",
    "\n",
    "with open(\"./vocab.tsv\", \"wt\") as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter=\"\\t\")\n",
    "    vocab_dict = vocab.get_itos()\n",
    "    for i in vocab_dict:\n",
    "        tsv_writer.writerow([i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the embedding space to see if we can find some meaningfull clusters.\n",
    "The figures shows the 100 nearest neighbors using cosine similarity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Embedding of gives](Figures\\Embedding_gives.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster of word: 'gives'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Embedding of two](Figures\\Embedding_two.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster of word: 'two'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Embedding of gazed](Figures\\Embedding_gazed.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster of word: 'Gazed'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualizing the embedding space, we found three words that showed some meaningful clustering, 'gives', 'two' and 'gazed'\n",
    "\n",
    "The word â€˜givesâ€™ has datapoints that are more spread but seem to be pointing in the same direction. The embedding shows words like â€˜gaveâ€™, â€˜giveâ€™, â€˜offeredâ€™, â€˜sentâ€™, â€˜givingâ€™ that are very similar.\n",
    "\n",
    "The word â€˜twoâ€™ seems to have a cluster that is less spread, and we find that the cluster includes different numbers like â€˜fourâ€™. â€˜eightâ€™, â€˜fifteenâ€™, â€˜sevenâ€™, â€˜nineâ€™ etc. There are also words like â€˜severalâ€™ and â€˜manyâ€™ in this cluster, so this cluster seems to represent quantity.\n",
    "\n",
    "The word â€˜gazedâ€™ gives a cluster more like the â€˜givesâ€™ cluster, where the points are more spread out but seem to be pointing in the same direction. Here we see similar words like â€˜glancedâ€™, â€˜lookedâ€™, â€˜gazingâ€™, â€˜lookingâ€™, â€˜staredâ€™, â€˜glancingâ€™ and â€˜glanceâ€™.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Conjugating be and have"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use your trained word embedding and define a simple MLP architecture, an MLP architecture\n",
    "that has first an attention layer (see section 4), as well as a RNN architecture to predict be\n",
    "and have conjugation given the context around the missing target. Use the same context\n",
    "size max len for both MLPs and RNNs, even though RNNs and attention layers could take a\n",
    "context size of arbitrary length. You are not allowed to use nn.LazyLinear in this project.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to define 3 networks:\n",
    "1. Simple MLP\n",
    "2. MLP with attention layer\n",
    "3. A recurrent neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our targets, we have 12 targets when we account for all conjuagtions of both 'be' and 'having'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjugate_be =[\"be\", \"been\", \"being\", \"am\", \"is\", \"are\", \"was\", \"were\"]\n",
    "conjugate_have = [\"have\", \"has\", \"had\", \"having\"]\n",
    "all_targets = (conjugate_be + conjugate_have)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our models and create our target dataset using our all_targets array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple MLP Model using the pretrained embeddings\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, pretrained_embeddings, num_classes, context_size, hidden_dim=128):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "        (_, embedding_dim) = pretrained_embeddings.shape\n",
    "        self.fc1 = nn.Linear(embedding_dim * context_size *2, hidden_dim) #Times 2 to get context around the target\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embeddings(inputs).view(inputs.shape[0], -1)\n",
    "        x = self.relu(self.fc1(embeddings))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# MLP Model with attention layer using the pretrained embeddings\n",
    "\n",
    "# 4.1 Positional encoding\n",
    "def positional_encoding(max_len, emb_dim):\n",
    "    P = torch.zeros((max_len, emb_dim))\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        for j in range(emb_dim // 2):\n",
    "            # Apply sin to even indices in the array; 2i\n",
    "            P[i, 2 * j] = np.sin(i / np.power(10000, (2 * j) / emb_dim))\n",
    "            # Apply cos to odd indices in the array; 2i+1\n",
    "            P[i, 2 * j + 1] = np.cos(i / np.power(10000, (2 * j) / emb_dim))\n",
    "    return P\n",
    "\n",
    "# 4.2 Simple-head dot-product self-attention\n",
    "class SimpleAttention(torch.nn.Module):\n",
    "    def __init__(self, emb_dim, p):\n",
    "        super(SimpleAttention, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.p = p\n",
    "        # weight matrices\n",
    "        self.Wq = torch.nn.Parameter(torch.randn(emb_dim, p))\n",
    "        self.Wk = torch.nn.Parameter(torch.randn(emb_dim, p))\n",
    "        self.Wv = torch.nn.Parameter(torch.randn(emb_dim, p))\n",
    "\n",
    "    def forward(self, Xf):\n",
    "        # Compute queries, keys, values\n",
    "        Q = torch.matmul(Xf, self.Wq)\n",
    "        K = torch.matmul(Xf, self.Wk)\n",
    "        V = torch.matmul(Xf, self.Wv)\n",
    "\n",
    "        # Compute the dot products of Q and K for the attention scores\n",
    "        scores = torch.bmm(Q, K.transpose(-2, -1)) / np.sqrt(self.p)\n",
    "\n",
    "        # Apply softmax to get the attention weights\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Compute the output of the attention layer\n",
    "        h = torch.bmm(attention_weights, V)\n",
    "\n",
    "        return h\n",
    "\n",
    "# 4.3 Multi-head attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, p, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.attention_heads = nn.ModuleList([SimpleAttention(emb_dim, p) for _ in range(n_head)])\n",
    "        self.Wo = nn.Linear(p * n_head, emb_dim)\n",
    "\n",
    "    def forward(self, Xf):\n",
    "        heads = [head(Xf) for head in self.attention_heads]\n",
    "        heads_concat = torch.cat(heads, dim=-1)\n",
    "        H = self.Wo(heads_concat) #Combine heads\n",
    "        return H\n",
    "\n",
    "# MLP Model with attention layer\n",
    "class MLPAttention(nn.Module):\n",
    "    def __init__(self, pretrained_embeddings, p, n_heads, max_len, num_classes):\n",
    "        super(MLPAttention, self).__init__()\n",
    "        # Pre-trained embeddings\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "        (_, emb_dim) = pretrained_embeddings.shape\n",
    "        #Positonal encoding with max_len*2 for context around target\n",
    "        self.pos_encoding = positional_encoding(max_len*2, emb_dim).to(device)\n",
    "        self.attention = MultiHeadAttention(emb_dim, p, n_heads)\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeddings = self.embeddings(input_ids)\n",
    "        # Add positional encoding\n",
    "        embeddings += self.pos_encoding[:embeddings.size(1), :]\n",
    "        #Attention\n",
    "        attention_output = self.attention(embeddings)    \n",
    "        x = F.relu((attention_output.mean(dim=1)))\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# RNN Model using pretrained embeddings\n",
    "class RecurrentNN(nn.Module):\n",
    "    def __init__(self, pretrained_embeddings, hidden_size, num_classes):\n",
    "        super(RecurrentNN, self).__init__()\n",
    "        (vocab_size, embedding_dim) = pretrained_embeddings.shape\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embeddings(x)\n",
    "        output, _ = self.rnn(embedded)                                           \n",
    "        out = output[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Function to create context target dataset \n",
    "def create_target_dataset(text, vocab, context_size=3, target_words=all_targets):\n",
    "    n_text = len(text)\n",
    "    txt = [vocab[w] for w in text]\n",
    "    contexts = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(context_size, n_text - context_size):\n",
    "        if vocab.lookup_token(txt[i]) in target_words:\n",
    "            c = txt[i-(context_size):i] + txt[i+1:i+1+(context_size)] #Context around the target\n",
    "            targets.append(target_words.index(vocab.lookup_token(txt[i])))\n",
    "            contexts.append(torch.tensor(c))\n",
    "\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    return TensorDataset(contexts, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train several models and select best based on validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Training SimpleMLP with batch size: 32, and learning rate: 0.1\n",
      "17:32:31.142442  |  Epoch 1  |  Training loss 1.94580\n",
      "17:32:36.244326  |  Epoch 2  |  Training loss 1.85612\n",
      "17:32:46.330994  |  Epoch 4  |  Training loss 1.83992\n",
      "17:32:56.311069  |  Epoch 6  |  Training loss 1.81631\n",
      "17:33:07.083825  |  Epoch 8  |  Training loss 1.81488\n",
      "MLP: Validation accuracy: 38.61%, Training Time: 41.05 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training SimpleMLP with batch size: 32, and learning rate: 0.01\n",
      "17:33:12.418409  |  Epoch 1  |  Training loss 1.26009\n",
      "17:33:17.955166  |  Epoch 2  |  Training loss 1.17409\n",
      "17:33:28.839519  |  Epoch 4  |  Training loss 1.13768\n",
      "17:33:39.547720  |  Epoch 6  |  Training loss 1.12298\n",
      "17:33:49.602359  |  Epoch 8  |  Training loss 1.10968\n",
      "MLP: Validation accuracy: 57.22%, Training Time: 42.48 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training SimpleMLP with batch size: 64, and learning rate: 0.1\n",
      "17:33:52.425785  |  Epoch 1  |  Training loss 1.67306\n",
      "17:33:55.451386  |  Epoch 2  |  Training loss 1.60905\n",
      "17:34:00.712406  |  Epoch 4  |  Training loss 1.59667\n",
      "17:34:06.776617  |  Epoch 6  |  Training loss 1.58760\n",
      "17:34:12.307370  |  Epoch 8  |  Training loss 1.58750\n",
      "MLP: Validation accuracy: 30.12%, Training Time: 22.67 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training SimpleMLP with batch size: 64, and learning rate: 0.01\n",
      "17:34:15.155816  |  Epoch 1  |  Training loss 1.23799\n",
      "17:34:17.981244  |  Epoch 2  |  Training loss 1.14156\n",
      "17:34:23.642108  |  Epoch 4  |  Training loss 1.09553\n",
      "17:34:29.485129  |  Epoch 6  |  Training loss 1.07262\n",
      "17:34:34.981353  |  Epoch 8  |  Training loss 1.05852\n",
      "MLP: Validation accuracy: 57.72%, Training Time: 22.64 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training MlpAttention with batch size: 32, and learning rate: 0.1\n",
      "17:35:00.798536  |  Epoch 1  |  Training loss 2.19595\n",
      "17:35:26.349491  |  Epoch 2  |  Training loss 2.17427\n",
      "17:36:17.924808  |  Epoch 4  |  Training loss 2.17477\n",
      "17:37:09.801883  |  Epoch 6  |  Training loss 2.17422\n",
      "17:38:01.515320  |  Epoch 8  |  Training loss 2.17420\n",
      "MLPAttention: Validation accuracy: 25.14%, Training Time: 206.49 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training MlpAttention with batch size: 32, and learning rate: 0.01\n",
      "17:38:27.112313  |  Epoch 1  |  Training loss 1.81323\n",
      "17:38:52.349498  |  Epoch 2  |  Training loss 1.74884\n",
      "17:39:42.876915  |  Epoch 4  |  Training loss 1.73032\n",
      "17:40:33.640535  |  Epoch 6  |  Training loss 1.64278\n",
      "17:41:24.555784  |  Epoch 8  |  Training loss 1.52570\n",
      "MLPAttention: Validation accuracy: 43.71%, Training Time: 202.93 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training MlpAttention with batch size: 64, and learning rate: 0.1\n",
      "17:41:37.847705  |  Epoch 1  |  Training loss 2.18628\n",
      "17:41:50.955467  |  Epoch 2  |  Training loss 2.17079\n",
      "17:42:16.781159  |  Epoch 4  |  Training loss 2.17050\n",
      "17:42:42.626867  |  Epoch 6  |  Training loss 2.17074\n",
      "17:43:08.427536  |  Epoch 8  |  Training loss 2.17098\n",
      "MLPAttention: Validation accuracy: 25.14%, Training Time: 103.76 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training MlpAttention with batch size: 64, and learning rate: 0.01\n",
      "17:43:21.555317  |  Epoch 1  |  Training loss 1.57406\n",
      "17:43:34.699611  |  Epoch 2  |  Training loss 1.47416\n",
      "17:44:01.021228  |  Epoch 4  |  Training loss 1.40743\n",
      "17:44:27.692145  |  Epoch 6  |  Training loss 1.39067\n",
      "17:44:53.637939  |  Epoch 8  |  Training loss 1.37196\n",
      "MLPAttention: Validation accuracy: 51.43%, Training Time: 105.10 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training RecurrentNN with batch size: 32, and learning rate: 0.1\n",
      "17:45:00.233607  |  Epoch 1  |  Training loss 2.24139\n",
      "17:45:06.971898  |  Epoch 2  |  Training loss 2.27653\n",
      "17:45:20.614619  |  Epoch 4  |  Training loss 2.28425\n",
      "17:45:33.733892  |  Epoch 6  |  Training loss 2.29929\n",
      "17:45:47.181448  |  Epoch 8  |  Training loss 2.29547\n",
      "RecurrentNN: Validation accuracy: 18.42%, Training Time: 53.43 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training RecurrentNN with batch size: 32, and learning rate: 0.01\n",
      "17:45:54.095888  |  Epoch 1  |  Training loss 1.52857\n",
      "17:46:01.191486  |  Epoch 2  |  Training loss 1.42144\n",
      "17:46:15.246063  |  Epoch 4  |  Training loss 1.40124\n",
      "17:46:29.024401  |  Epoch 6  |  Training loss 1.39917\n",
      "17:46:42.807745  |  Epoch 8  |  Training loss 1.40084\n",
      "RecurrentNN: Validation accuracy: 50.93%, Training Time: 55.58 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training RecurrentNN with batch size: 64, and learning rate: 0.1\n",
      "17:46:46.632031  |  Epoch 1  |  Training loss 2.14505\n",
      "17:46:50.417784  |  Epoch 2  |  Training loss 2.18749\n",
      "17:46:58.054346  |  Epoch 4  |  Training loss 2.20713\n",
      "17:47:05.722936  |  Epoch 6  |  Training loss 2.20900\n",
      "17:47:13.396029  |  Epoch 8  |  Training loss 2.21705\n",
      "RecurrentNN: Validation accuracy: 18.80%, Training Time: 30.55 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Training RecurrentNN with batch size: 64, and learning rate: 0.01\n",
      "17:47:17.283368  |  Epoch 1  |  Training loss 1.52714\n",
      "17:47:21.129674  |  Epoch 2  |  Training loss 1.40848\n",
      "17:47:28.879833  |  Epoch 4  |  Training loss 1.36083\n",
      "17:47:36.178604  |  Epoch 6  |  Training loss 1.34493\n",
      "17:47:43.477376  |  Epoch 8  |  Training loss 1.34125\n",
      "RecurrentNN: Validation accuracy: 50.69%, Training Time: 30.04 seconds\n",
      "-------------------- Modelselection complete --------------------\n",
      "Best Model is MLP with batch size: 64, and learning rate: 0.01\n",
      "Best Model Validation Accuracy: 57.72% And it's training time was 22.64 seconds\n"
     ]
    }
   ],
   "source": [
    "n_epochs_conj = 8 # Small number of epochs to speed up training time\n",
    "loss_fn_conj = nn.CrossEntropyLoss() #Use crossEntropy since we do not do softmax on output\n",
    "max_len = 3 # Same max_len for all\n",
    "\n",
    "#Create validation and training dataset\n",
    "val_data_conj = create_target_dataset(words_val, vocab, context_size=max_len, target_words=all_targets)\n",
    "train_data_conj = create_target_dataset(words_train, vocab, context_size=max_len, target_words=all_targets)\n",
    "\n",
    "# Validation loader with a batch size of 64\n",
    "val_loader_conj = DataLoader(val_data_conj, batch_size=64, shuffle=False)\n",
    "\n",
    "#Init best parametres\n",
    "best_model = None\n",
    "best_time = 0\n",
    "best_batch = 0\n",
    "best_lr = 0\n",
    "best_v_acc = 0\n",
    "\n",
    "#Hyperparams\n",
    "model_architectures = ['SimpleMLP', 'MlpAttention', 'RecurrentNN']\n",
    "batch_size = [32, 64]\n",
    "lr_list = [0.1, 0.01]\n",
    "\n",
    "for model_cls in model_architectures:\n",
    "    for bs in batch_size:\n",
    "        for lr in lr_list:\n",
    "            print(\"----------------------------------------------------------------------------\")\n",
    "            print(f\"Training {model_cls} with batch size: {bs}, and learning rate: {lr}\")\n",
    "\n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "            if model_cls == 'SimpleMLP':\n",
    "                model = MLP(pretrained_embeddings=net_emb_w, context_size=max_len,\n",
    "                                 num_classes=len(all_targets)).to(device=device)\n",
    "            elif model_cls == 'MlpAttention':\n",
    "                model = MLPAttention(pretrained_embeddings=net_emb_w, p=32, n_heads = 12, \n",
    "                                     max_len=max_len, num_classes=len(all_targets)).to(device=device)\n",
    "\n",
    "            elif model_cls == 'RecurrentNN':\n",
    "                model = RecurrentNN(pretrained_embeddings=net_emb_w, hidden_size=12, \n",
    "                                        num_classes=len(all_targets)).to(device=device)\n",
    "\n",
    "\n",
    "            train_loader = DataLoader(train_data_conj, batch_size=bs, shuffle=True)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            # Train the model\n",
    "            train(n_epochs=n_epochs_conj, model=model, optimizer=optimizer, loss_fn=loss_fn_conj, train_loader=train_loader)\n",
    "            \n",
    "            # Training time\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            # Validation Accuracy\n",
    "            val_acc = compute_accuracy(model, val_loader_conj, device)\n",
    "\n",
    "            print(f\"{model._get_name()}: Validation accuracy: {val_acc:.2%}, Training Time: {elapsed_time:.2f} seconds\")\n",
    "            if val_acc > best_v_acc:\n",
    "                best_batch = bs\n",
    "                best_lr = lr\n",
    "                best_v_acc = val_acc\n",
    "                best_model = model\n",
    "                best_time = elapsed_time\n",
    "\n",
    "# Output the best model and hyperparams\n",
    "print(\"-------------------- Modelselection complete --------------------\")\n",
    "print(f\"Best Model is {best_model._get_name()} with batch size: {best_batch}, and learning rate: {best_lr}\")\n",
    "print(f\"Best Model Validation Accuracy: {best_v_acc:.2%} And it's training time was {best_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbiased estimate of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of best model 57.72%\n"
     ]
    }
   ],
   "source": [
    "test_data_conj = create_target_dataset(words_val, vocab, context_size=max_len, target_words=all_targets)\n",
    "\n",
    "test_loader_conj = DataLoader(test_data_conj, batch_size=64, shuffle=False)\n",
    "tes_accuracy_conj = compute_accuracy(best_model, test_loader_conj, device=device)\n",
    "print(f\"Test accuracy of best model {tes_accuracy_conj:.2%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the three different architectures with 8 epochs and with 4 different combinations of hyperparameters.\n",
    "this gives us a total of 12 models. \n",
    "\n",
    "All the RNNs we train use the same hidden_size = 12. All of The MLPs with attention layer uses the same amount of heads n_heads=12 and a p value of p=32\n",
    "\n",
    "The small number of epochs is due to time, as it takes quite a while to train the models if we increase it to much.\n",
    "\n",
    "\n",
    "We then measure the validation accuracy after each training to find the best model. If we look at the training times we can see that the MLPs with a single\n",
    "attention layer seemed to take the longest to train with around 220 seconds.\n",
    "While the simple MLP and the RNN used much shorter time, with the RNN using least amount of time. We also notice that the training times shorten when we increase the batch size.\n",
    "\n",
    "\n",
    "Our validation accuracies range all the way from 18.42% when using a large learning rate to our\n",
    "best model with 57.72% accuracy. It does seem like the learning rate plays a big role in the accuracies of the models, idealy\n",
    "we would test more learning rates but due to time constraints this was not possible. The final selected model was a simple MLP with batch size 64 and\n",
    "learning rate 0.01, and a training time of around 22 seconds. This is a bit suprising as we assumed the MLP with attention would perform best, but this is presumably not the case since we only use one attention layer here.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Text Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a RNN architecture that can predict the next word given the context before the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRNN(nn.Module):\n",
    "    def __init__(self, pretrained_embeddings, hidden_size):\n",
    "        super(TextRNN, self).__init__()\n",
    "        (vocab_size, embedding_dim) = pretrained_embeddings.shape\n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, VOCAB_SIZE)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embeddings(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        out = output[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return self.softmax(out)  # Returning log probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with batch_size=512 and lr=0.01\n",
      "17:48:28.189295  |  Epoch 1  |  Training loss 4.28182\n",
      "17:48:55.498761  |  Epoch 2  |  Training loss 4.18086\n",
      "17:49:49.514675  |  Epoch 4  |  Training loss 4.16636\n",
      "17:50:16.654495  |  Epoch 5  |  Training loss 4.15735\n",
      "Model: validation accuracy:0.20759023247359173\n",
      "Training model with batch_size=512 and lr=0.001\n",
      "17:50:44.821699  |  Epoch 1  |  Training loss 4.62276\n",
      "17:51:10.681419  |  Epoch 2  |  Training loss 4.29648\n",
      "17:52:00.406645  |  Epoch 4  |  Training loss 4.20922\n",
      "17:52:26.402983  |  Epoch 5  |  Training loss 4.19087\n",
      "Model: validation accuracy:0.2063177879663105\n",
      "Training model with batch_size=1024 and lr=0.01\n",
      "17:52:48.621073  |  Epoch 1  |  Training loss 4.33052\n",
      "17:53:09.872835  |  Epoch 2  |  Training loss 4.17568\n",
      "17:53:52.083105  |  Epoch 4  |  Training loss 4.14742\n",
      "17:54:14.112533  |  Epoch 5  |  Training loss 4.14223\n",
      "Model: validation accuracy:0.20769122013289976\n",
      "Training model with batch_size=1024 and lr=0.001\n",
      "17:54:36.285085  |  Epoch 1  |  Training loss 4.76023\n",
      "17:54:57.856121  |  Epoch 2  |  Training loss 4.34087\n",
      "17:55:40.451220  |  Epoch 4  |  Training loss 4.23892\n",
      "17:56:02.060289  |  Epoch 5  |  Training loss 4.21652\n",
      "Model: validation accuracy:0.20518672618206055\n",
      "Final best model is a model with batch size: 1024, and learning rate: 0.01 \n",
      "\n",
      "Best model: validation accuracy: 20.77%\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 15 \n",
    "\n",
    "train_data = create_dataset(words_train, vocab, context_size=sequence_length)\n",
    "val_data = create_dataset(words_val, vocab, context_size=sequence_length)\n",
    "\n",
    "batch_size = [512, 1024]\n",
    "lr_list = [0.01, 0.001]\n",
    "hidden_size = 12\n",
    "\n",
    "#Init best parametres\n",
    "best_model = None\n",
    "best_batch = 0\n",
    "best_lr = 0\n",
    "best_v_acc = 0\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "for bs in batch_size:\n",
    "    for lr in lr_list:\n",
    "        model = TextRNN(net_emb_w, hidden_size)\n",
    "        train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)        \n",
    "        model.to(device)        \n",
    "\n",
    "        print(f'Training model with batch_size={bs} and lr={lr}')\n",
    "        train(n_epochs=5, model=model, optimizer=optimizer, loss_fn=loss_fn, train_loader=train_loader)\n",
    "\n",
    "\n",
    "        val_acc = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "        print(f\"Model: validation accuracy:{val_acc}\")\n",
    "        if val_acc > best_v_acc:\n",
    "            best_batch = bs\n",
    "            best_lr = lr\n",
    "            best_v_acc = val_acc\n",
    "            best_model = model\n",
    "\n",
    "print(f\"Final best model is a model with batch size: {best_batch}, and learning rate: {best_lr} \")\n",
    "print()\n",
    "print(f\"Best model: validation accuracy: {best_v_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of best model 24.61%\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "tes_accuracy = compute_accuracy(best_model, test_loader, device=device)\n",
    "print(f\"Test accuracy of best model {tes_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(model, initial_words, vocab, n_words=10, beam_width=3):\n",
    "    unk_index = vocab['<unk>']  \n",
    "    initial_indices = [vocab[w] for w in initial_words]\n",
    "    candidates = [(initial_indices, 0)]\n",
    "\n",
    "    for _ in range(n_words):\n",
    "        new_candidates = []\n",
    "        for seq, score in candidates:\n",
    "            input_tensor = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_tensor)\n",
    "                probabilities = torch.exp(logits).view(-1)  \n",
    "                topk_probs, topk_indices = probabilities.topk(beam_width)\n",
    "\n",
    "            for i in range(beam_width):\n",
    "                if topk_indices[i].item() != unk_index:  \n",
    "                    new_seq = seq + [topk_indices[i].item()]\n",
    "                    new_score = score - np.log(topk_probs[i].item())  \n",
    "                    new_candidates.append((new_seq, new_score))\n",
    "\n",
    "        candidates = sorted(new_candidates, key=lambda x: x[1])[:beam_width]\n",
    "\n",
    "    return ' '.join([vocab.get_itos()[i] for i in candidates[0][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the king and i had been at the door , and he had been\n"
     ]
    }
   ],
   "source": [
    "initial_words = [\"the\", \"king\", \"and\", \"i\"] \n",
    "generated_text = beam_search(best_model, initial_words, vocab, n_words=10, beam_width=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you and i know me . i shall not know that i have\n"
     ]
    }
   ],
   "source": [
    "initial_words = [\"you\", \"and\", \"i\"] \n",
    "generated_text = beam_search(best_model, initial_words, vocab, n_words=10, beam_width=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horses are big , and he had been at the door , and\n"
     ]
    }
   ],
   "source": [
    "initial_words = [\"horses\", \"are\", \"big\"] \n",
    "generated_text = beam_search(best_model, initial_words, vocab, n_words=10, beam_width=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested with some words to try and make some sentences, they are generaly understandable but not the best. In the report we tested some more sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "847d36dd74d3db7bcac89bf357c370f015c294bfb16cb92561a1974142bc3141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
